{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도를 향상시키기 위해 모델들을 결합하는 머신러닝 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 모델에서 발생하는 오류는 크게 세가지로 나눔"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Bias error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 값과 예측 값이 얼마나 다른지를 평균화하는데 유용함.\n",
    "바이어스 오류가 높다는 것은 중요한 추세가 누락 된 성능이 낮은 모델을 의미함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동일한 관측에 대한 예측이 어떻게 다른지 정량화함\n",
    "분산 모델이 높으면  training population에서 over-fit하게 되고,\n",
    "training이 아닌 관측에서는 성능이 저하됨.\n",
    "즉, 추정 값들의 흩어진 정도를 의미함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델은 Bias error와 Variance error간에 균형을 유지해야 하며, \n",
    "bias-variance errors의  trade-off management 라고 함.\n",
    "앙상블 학습은 이러한 trade-off management 을 수행하는 한 가지 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측 변수 그룹 = 앙상블. \n",
    " ex) 수천 명의 임의의 사람들에게 복잡한 질문을 한 다음 답변을 집계한다고 가정하자. 많은 경우에 집계된 답변이 전문가의 답변보다 낫다는 것을 알게 될 것이고, 이를 군중의 지혜라고 함.\n",
    "마찬가지로, 예측 변수 그룹 (예 : 의사 결정 트리 분류 자, SVM, 로지스틱 회귀)의 예측을 집계하면 최상의 개별 예측 변수보다 더 나은 예측을 얻을 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Types of ensembling\n",
    "##   3.1 Basic Ensemble Techniques\n",
    "###    3.1.1Max Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 분류 문제에 사용.\n",
    "ex) 5명에게 영화를 평가를 요청했을 때, 우리는 3명은 4점으로, 2명은 5점으로 평가했다고 하자. 대다수가 4점을 부여했으므로 최종 평가는 4점으로 간주함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다수결처리를 어떻게 하느냐는 hard voting과 soft voting로 나뉨.\n",
    "1. Hard Voting (단순투표)\n",
    "2. Soft voting - 투표에 가중치를 부여(조건부 확률의 합)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    3.1.2Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 model에서 평균 예측을 가져 와서 최종 예측에 사용함.\n",
    "평균화는 회귀 문제에서 예측을 하거나 분류 문제의 확률을 계산하는 데 사용할 수 있음.\n",
    "평균화 방법은 모든 값의 평균을 취함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.1.3Weighted Average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 모델의 중요성을 정의하는 서로 다른 가중치가 할당됨.\n",
    "ex) 동료 중 두 명이 전문가이고 다른 사람이이 분야에 대한 사전 경험이 없는 경우, 다른 두 사람에 비해 두 명의 답변이 더 중요함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Advanced Ensemble Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.2.1Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stability and Accuracy.\n",
    "각 예측 set를 저장하고 이를 평균화하면 편차에 영향을 주지 않고 분산을 낮출뿐만 아니라 정확도를 향상시킬 수 있음. 많은 다른 모델들을 만들고 함께 모으면 과적합을 피하고, 예측을 안정화하며 정확도를 높일 수 있음.\n",
    "데이터엔 variance가 존재하고, 그렇지않다면 bagging은 도움이 되지 않음.\n",
    "배깅은  bootstrapping의 통계적 방법을 기반으로 함.\n",
    "\n",
    "1. 대체를 통해 subset을 만듬.\n",
    "2. 샘플의 모든 subset에 모델을 적용함.\n",
    "3. 모델은 병렬로 실행되며 서로 독립적임.\n",
    "4. 각 모델을 사용하여 x- text 예측\n",
    "5. 예측을 집계(투표 또는 평균화)하여 최종 예측을 형성."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Bagging algorithms\n",
    "### 3.3.1 Bagging meta-estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging meta-estimator는 분류 (BaggingClassifier) 및 회귀 (BaggingRegressor) 문제 모두에 사용할 수 있는  앙상블 알고리즘.\n",
    "예측을 위해 전형적인 배깅을 사용함.\n",
    "bagging meta-estimator 알고리즘의 단계는 다음과 같음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 랜덤 sub set은 원래 데이터 세트 (부트 스트랩)에서 작성.\n",
    "2. 데이터 집합의 하위 집합에는 모든 기능이 포함.\n",
    "3. 이러한 작은 set 각각에 사용자 지정 기준 추정기가 장착되어 있음.\n",
    "4. 각 모델의 예측은 최종 결과를 얻기 위해 결합.\n",
    "\n",
    "-base_estimator : 데이터 세트의 임의의 서브 세트에 맞도록 기본 추정기를 정의. 아무것도 지정하지 않으면 기본 추정기는 의사결정나무.\n",
    "-n_estimators : 생성 할 기본 추정기의 수. 많으면 실행하는 데 시간이 오래 걸리고 소수의 경우 최상의 결과를 얻지 못할 수 있으므로 추정기 수는 신중하게 조정해야 함.\n",
    "-max_samples : sub set의 크기를 제어. 각 기본 추정기를 훈련시키는 최대 샘플 수.\n",
    "-max_features : 전체 data set에서 그릴 피처 수를 제어. 각 기본 추정기를 훈련시키는 데 필요한 최대 기능 수를 정의.\n",
    "-n_jobs: 병렬로 실행할 작업 수. 이 값을 시스템의 코어와 동일하게 설정해야 함. -1이면 작업 수는 코어 수로 설정.\n",
    "-random_state : 랜덤 분할 방법 지정. 임의의 상태 값이 두 모델에서 동일하면 임의 선택이 두 모델에서 동일함. 이 매개 변수는 다른 모델을 비교할 때 유용함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤 포레스트는 배깅 기술을 따르는 또 다른 앙상블 머신 러닝 알고리즘. \n",
    "이는 bagging estimator 알고리즘의 연장으로 볼 수 있음.\n",
    "random forest의 기본 estimator는 결정 트리이고, random forest는 결정 트리의 각 노드에서 최상의 분할을 결정하는 데 사용되는 feature set을 무작위로 선택.\n",
    "\n",
    "1.Random subset은 원래 data set(bootstrapping)에서 형성.\n",
    "2.결정 트리의 각 노드에서 최상의 분할을 정하기 위해 임의의 feature set만 고려됨.\n",
    "3.각 하위 집합에 의사결정 트리 모델이 장착되고, 최종 예측은 모든 결정 트리의 예측을 평균하여 계산됨.\n",
    "\n",
    " +) random forest의 결정 트리는 data 및 feature의 sub set을 기반으로 구축 할 수 있음. 특히 random forrest의 sklearn 모델은 결정 트리에 모든 기능을 사용하며 각 노드에서 분할하기 위해 feature의 sub set이 임의로 선택됨.\n",
    "\n",
    "즉, 랜덤 포레스트는 임의로 데이터 포인트와 기능을 선택하고 여러 트리를 생성."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Boosting\n",
    "부스팅은 weak learner를 strong learner로 전환시키는 알고리즘 군을 의미.\n",
    "부스팅은 주어진 학습 알고리즘의 모델 예측을 개선하기위한 앙상블 방법.\n",
    "부스팅의 개념은 weak learner들을 순차적으로 훈련시키는 것.\n",
    "부스팅은 \"팀워크\"에 관한 것\n",
    " -> 실행되는 각 모델은 다음 모델이 집중할 feature를 결정."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 AdaBoost\n",
    "어댑티브 부스팅 또는 AdaBoost는 가장 간단한 부스팅 알고리즘 중 하나.\n",
    "일반적으로  결정 트리는 모델링에 사용되고, 마지막 모델의 오류를 수정하는 여러 순차 모델이 작성됨.\n",
    "AdaBoost는 잘못 예측 된 관측치에 가중치를 할당하고 후속 모델은 이러한 값을 올바르게 예측.\n",
    "\n",
    "1. 데이터 세트의 모든 관측치에 동일한 가중치가 부여.\n",
    "2. 모델은 데이터의 하위 집합을 기반으로 함.\n",
    "3. 이 모델을 사용하여 전체 data set에 대한 예측이 이루어짐.\n",
    "4. 오류는 예측과 실제 값을 비교하여 계산.\n",
    "5.  다음 모델을 생성하는 동안 잘못 예측 된 데이터 포인트에 더 높은 가중치 부여.\n",
    "6. 오차 값을 사용하여 가중치를 결정할 수 있습니다. 예를 들어, 오차가 높을수록 관측치에 할당 된 가중치가 더 커짐.\n",
    "7. 이 과정은 error function이 변경되지 않거나 추정기 수의 최대 한계에 도달 할 때까지 반복.\n",
    "\n",
    "#### Parameters\n",
    "- base_estimators: 기본 추정기의 유형, 즉 기본 학습자로 사용될 기계 학습 알고리즘을 지정하는 데 도움이 됨.\n",
    "- n_estimators:  기본 추정기의 수. 기본값은 10이지만 더 나은 성능을 얻으려면 더 높은 값을 유지해야 함.\n",
    "- learning_rate: 이 매개 변수는 최종 조합에서 추정량의 기여도를 제어함. learning_rate와 n_estimators 사이에는 상충 관계가 있음.\n",
    "- max_depth: 개별 추정기의 최대 깊이를 정의. 최상의 성능을 위해이 매개 변수를 조정.\n",
    "- n_jobs: 사용할 수있는 프로세서 수를 지정. 최대 프로세서 허용 값을 –1로 설정.\n",
    "- random_state : 랜덤 데이터 분할을 지정하는 정수 값. random_state의 한정된 값은 동일한 매개 변수 및 학습 데이터가 제공되는 경우 항상 동일한 결과를 생성.\n",
    "\n",
    "#### stacking\n",
    "부스팅과 유사하게 원본 데이터에 여러 모델을 적용 할 수도 있음. 차이점은 가중치 함수에 대한 경험적 공식이 아니라 메타 레벨을 도입하고 다른 모델 , 접근법을 사용하여 가중치를 추정하기 위해 모든 모델의 output과 함께 input을 추정하는 것.\n",
    "즉, 어떤 모델이 잘 수행되고 어떤 입력 데이터에 나쁜 영향을 주었는지 확인하는 것"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
