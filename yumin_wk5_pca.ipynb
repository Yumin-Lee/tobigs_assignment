{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 반갑습니다 13기 여러분\n",
    "\n",
    "과제를 진행해 볼게요\n",
    "\n",
    "혹시라도 도저히 모르겠거나 해결이 안되신다면 01040493041로 전화주시거나 카톡주세요!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ''' ? ''' 이 있는 부분을 채워주시면 됩니다\n",
    "\n",
    "나는 내 스타일로 하겠다 하시면 그냥 구현 하셔도 됩니다!!\n",
    "\n",
    "참고하셔야 하는 함수들은 링크 달아드렸으니 들어가서 확인해보세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) PCA의 과정을 한번 차근차근 밟아 볼거에요 잘 따라 오세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as lin\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#  기본 모듈들을 불러와 줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [95, 91, 66, 94, 68, 63, 12, 73, 93, 51, 13, 70, 63, 63, 97, 56, 67, 96, 75, 6]\n",
    "x2 = [56, 27, 25, 1, 9, 80, 92, 69, 6, 25, 83, 82, 54, 97, 66, 93, 76, 59, 94, 9]\n",
    "x3 = [57, 34, 9, 79, 4, 77, 100, 42, 6, 96, 61, 66, 9, 25, 84, 46, 16, 63, 53, 30]\n",
    "\n",
    "#   설명변수 x1, x2, x3의 값이 이렇게 있네요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack((x1,x2,x3),axis=0)\n",
    "\n",
    "# 설명변수들을 하나의 행렬로 만들어 줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X.T, columns=['x1','x2','x3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>92</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "      <td>69</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>25</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>83</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "      <td>82</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>63</td>\n",
       "      <td>97</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "      <td>93</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>67</td>\n",
       "      <td>76</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>96</td>\n",
       "      <td>59</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>75</td>\n",
       "      <td>94</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1  x2   x3\n",
       "0   95  56   57\n",
       "1   91  27   34\n",
       "2   66  25    9\n",
       "3   94   1   79\n",
       "4   68   9    4\n",
       "5   63  80   77\n",
       "6   12  92  100\n",
       "7   73  69   42\n",
       "8   93   6    6\n",
       "9   51  25   96\n",
       "10  13  83   61\n",
       "11  70  82   66\n",
       "12  63  54    9\n",
       "13  63  97   25\n",
       "14  97  66   84\n",
       "15  56  93   46\n",
       "16  67  76   16\n",
       "17  96  59   63\n",
       "18  75  94   53\n",
       "19   6   9   30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-1) 먼저 PCA를 시작하기 전에 항상!!!!!! 데이터를 scaling 해주어야 해요\n",
    "\n",
    "https://datascienceschool.net/view-notebook/f43be7d6515b48c0beb909826993c856/ 를 참고하시면 도움이 될거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.08573604,  0.02614175,  0.30684189],\n",
       "       [ 0.93801686, -0.86575334, -0.46445467],\n",
       "       [ 0.01477192, -0.92726334, -1.30282049],\n",
       "       [ 1.04880625, -1.66538341,  1.04460382],\n",
       "       [ 0.08863151, -1.41934339, -1.47049366],\n",
       "       [-0.09601747,  0.76426183,  0.97753455],\n",
       "       [-1.97943714,  1.13332186,  1.74883111],\n",
       "       [ 0.2732805 ,  0.42595679, -0.1961776 ],\n",
       "       [ 1.01187645, -1.5116084 , -1.40342439],\n",
       "       [-0.53917504, -0.92726334,  1.61469258],\n",
       "       [-1.94250735,  0.85652683,  0.44098042],\n",
       "       [ 0.16249111,  0.82577183,  0.60865359],\n",
       "       [-0.09601747, -0.03536825, -1.30282049],\n",
       "       [-0.09601747,  1.28709688, -0.76626636],\n",
       "       [ 1.15959564,  0.33369178,  1.21227698],\n",
       "       [-0.35452606,  1.16407687, -0.06203907],\n",
       "       [ 0.05170172,  0.64124181, -1.06807806],\n",
       "       [ 1.12266584,  0.11840676,  0.50804969],\n",
       "       [ 0.3471401 ,  1.19483187,  0.17270336],\n",
       "       [-2.20101593, -1.41934339, -0.5985932 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_std.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.08573604,  0.93801686,  0.01477192,  1.04880625,  0.08863151,\n",
       "        -0.09601747, -1.97943714,  0.2732805 ,  1.01187645, -0.53917504,\n",
       "        -1.94250735,  0.16249111, -0.09601747, -0.09601747,  1.15959564,\n",
       "        -0.35452606,  0.05170172,  1.12266584,  0.3471401 , -2.20101593],\n",
       "       [ 0.02614175, -0.86575334, -0.92726334, -1.66538341, -1.41934339,\n",
       "         0.76426183,  1.13332186,  0.42595679, -1.5116084 , -0.92726334,\n",
       "         0.85652683,  0.82577183, -0.03536825,  1.28709688,  0.33369178,\n",
       "         1.16407687,  0.64124181,  0.11840676,  1.19483187, -1.41934339],\n",
       "       [ 0.30684189, -0.46445467, -1.30282049,  1.04460382, -1.47049366,\n",
       "         0.97753455,  1.74883111, -0.1961776 , -1.40342439,  1.61469258,\n",
       "         0.44098042,  0.60865359, -1.30282049, -0.76626636,  1.21227698,\n",
       "        -0.06203907, -1.06807806,  0.50804969,  0.17270336, -0.5985932 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-2) 자 그럼 공분산 행렬을 구해볼게요\\\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.cov.html 를 참고하시면 도움이 될거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cov_matrix = np.cov(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.05263158, -0.2037104 , -0.12079228],\n",
       "       [-0.2037104 ,  1.05263158,  0.3125801 ],\n",
       "       [-0.12079228,  0.3125801 ,  1.05263158]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-3) 이제 고유값과 고유벡터를 구해볼게요\n",
    "\n",
    "방법은 실습코드에 있어요!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues = lin.eig(cov_matrix)[0]\n",
    "eigenvectors = lin.eig(cov_matrix)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.48756162, 0.94435407, 0.72597904]),\n",
       " array([[ 0.47018528, -0.85137353, -0.23257022],\n",
       "        [-0.64960236, -0.15545725, -0.74421087],\n",
       "        [-0.59744671, -0.50099516,  0.62614797]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin.eig(cov_matrix) # 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.48756162 0.94435407 0.72597904]\n",
      "[[ 0.47018528 -0.85137353 -0.23257022]\n",
      " [-0.64960236 -0.15545725 -0.74421087]\n",
      " [-0.59744671 -0.50099516  0.62614797]]\n"
     ]
    }
   ],
   "source": [
    "print(eigenvalues)\n",
    "print(eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.zeros((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat[0][0] = eigenvalues[0]\n",
    "mat[1][1] = eigenvalues[1]\n",
    "mat[2][2] = eigenvalues[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.48756162, 0.        , 0.        ],\n",
       "       [0.        , 0.94435407, 0.        ],\n",
       "       [0.        , 0.        , 0.72597904]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-4) 자 이제 고유값 분해를 할 모든 준비가 되었어요 고유값 분해의 곱으로 원래 공분산 행렬을 구해보세요\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html 를 참고해서 행렬 끼리 곱하시면 됩니다\n",
    "\n",
    "행렬 곱으로 eigenvector x mat x eigenvector.T 하면 될거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.05263158, -0.2037104 , -0.12079228],\n",
       "       [-0.2037104 ,  1.05263158,  0.3125801 ],\n",
       "       [-0.12079228,  0.3125801 ,  1.05263158]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.dot(eigenvectors,mat), eigenvectors.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-5) 마지막으로 고유 벡터 축으로 값을 변환해 볼게요\n",
    "\n",
    "함수로 한번 정의해 보았어요\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이해 Re\n",
    "def new_coordinates(X,eigenvectors):\n",
    "    for i in range(eigenvectors.shape[0]):\n",
    "        if i == 0:\n",
    "            new = [X.dot(eigenvectors.T[i])]\n",
    "        else:\n",
    "            new = np.concatenate((new,[X.dot(eigenvectors.T[i])]),axis=0)\n",
    "    return new.T\n",
    "\n",
    "# 모든 고유 벡터 축으로 데이터를 projection한 값입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31019368, -1.08215716, -0.07983642],\n",
       "       [ 1.28092404, -0.43132556,  0.13533091],\n",
       "       [ 1.38766381,  0.78428014, -0.12911446],\n",
       "       [ 0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [ 1.84222365,  0.88189889,  0.11493111],\n",
       "       [-1.12563709, -0.52680338,  0.06564012],\n",
       "       [-2.71174416,  0.63290138,  0.71195473],\n",
       "       [-0.03100441, -0.20059783, -0.50339479],\n",
       "       [ 2.29618509,  0.07661447,  0.01087174],\n",
       "       [-0.61585248, -0.205764  ,  1.82651199],\n",
       "       [-1.73320252,  1.29971699,  0.09045178],\n",
       "       [-0.82366049, -0.57164535, -0.27123176],\n",
       "       [ 0.75619512,  0.73995175, -0.76710616],\n",
       "       [-0.42344386,  0.26555394, -1.41533681],\n",
       "       [-0.39581307, -1.64646874,  0.24104031],\n",
       "       [-0.88581498,  0.15195119, -0.82271209],\n",
       "       [ 0.24587691,  0.39139878, -1.15801831],\n",
       "       [ 0.14741103, -1.22874561, -0.03110396],\n",
       "       [-0.7161265 , -0.56781471, -0.86180345],\n",
       "       [ 0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_coordinates(X_std,eigenvectors)\n",
    "\n",
    "# 새로운 축으로 변환되어 나타난 데이터들입니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) PCA를 구현해 보세요\n",
    "\n",
    "위의 과정을 이해하셨다면 충분히 하실 수 있을거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def MYPCA(X,number):\n",
    "    scaler = StandardScaler()\n",
    "    x_std = scaler.fit_transform(X)\n",
    "    features = x_std.T\n",
    "    cov_matrix = np.cov(features)\n",
    "    \n",
    "    eigenvalues = lin.eig(cov_matrix)[0]\n",
    "    eigenvectors = lin.eig(cov_matrix)[1]\n",
    "    \n",
    "    new_coordinates(x_std,eigenvectors)\n",
    "    \n",
    "    new_coordinate = new_coordinates(x_std,eigenvectors)\n",
    "    \n",
    "    index = eigenvalues.argsort()\n",
    "    index = list(index)\n",
    "    \n",
    "    for i in range(number):\n",
    "        if i==0:\n",
    "            new = [new_coordinate[:,index.index(i)]]\n",
    "        else:\n",
    "            new = np.concatenate(([new_coordinate[:,index.index(i)]],new),axis=0)\n",
    "    return new.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31019368, -1.08215716, -0.07983642],\n",
       "       [ 1.28092404, -0.43132556,  0.13533091],\n",
       "       [ 1.38766381,  0.78428014, -0.12911446],\n",
       "       [ 0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [ 1.84222365,  0.88189889,  0.11493111],\n",
       "       [-1.12563709, -0.52680338,  0.06564012],\n",
       "       [-2.71174416,  0.63290138,  0.71195473],\n",
       "       [-0.03100441, -0.20059783, -0.50339479],\n",
       "       [ 2.29618509,  0.07661447,  0.01087174],\n",
       "       [-0.61585248, -0.205764  ,  1.82651199],\n",
       "       [-1.73320252,  1.29971699,  0.09045178],\n",
       "       [-0.82366049, -0.57164535, -0.27123176],\n",
       "       [ 0.75619512,  0.73995175, -0.76710616],\n",
       "       [-0.42344386,  0.26555394, -1.41533681],\n",
       "       [-0.39581307, -1.64646874,  0.24104031],\n",
       "       [-0.88581498,  0.15195119, -0.82271209],\n",
       "       [ 0.24587691,  0.39139878, -1.15801831],\n",
       "       [ 0.14741103, -1.22874561, -0.03110396],\n",
       "       [-0.7161265 , -0.56781471, -0.86180345],\n",
       "       [ 0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MYPCA(X,3)\n",
    "\n",
    "# 새로운 축으로 잘 변환되어서 나타나나요?\n",
    "# 위에서 했던 PCA랑은 차이가 있을 수 있어요 왜냐하면 위에서는 고유값이 큰 축 순서로 정렬을 안했었거든요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) sklearn이랑 비교를 해볼까요?\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html 를 참고하시면 도움이 될거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3) # n_components가 3차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31019368, -1.08215716, -0.07983642],\n",
       "       [-1.28092404, -0.43132556,  0.13533091],\n",
       "       [-1.38766381,  0.78428014, -0.12911446],\n",
       "       [-0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [-1.84222365,  0.88189889,  0.11493111],\n",
       "       [ 1.12563709, -0.52680338,  0.06564012],\n",
       "       [ 2.71174416,  0.63290138,  0.71195473],\n",
       "       [ 0.03100441, -0.20059783, -0.50339479],\n",
       "       [-2.29618509,  0.07661447,  0.01087174],\n",
       "       [ 0.61585248, -0.205764  ,  1.82651199],\n",
       "       [ 1.73320252,  1.29971699,  0.09045178],\n",
       "       [ 0.82366049, -0.57164535, -0.27123176],\n",
       "       [-0.75619512,  0.73995175, -0.76710616],\n",
       "       [ 0.42344386,  0.26555394, -1.41533681],\n",
       "       [ 0.39581307, -1.64646874,  0.24104031],\n",
       "       [ 0.88581498,  0.15195119, -0.82271209],\n",
       "       [-0.24587691,  0.39139878, -1.15801831],\n",
       "       [-0.14741103, -1.22874561, -0.03110396],\n",
       "       [ 0.7161265 , -0.56781471, -0.86180345],\n",
       "       [-0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31019368, -1.08215716, -0.07983642],\n",
       "       [ 1.28092404, -0.43132556,  0.13533091],\n",
       "       [ 1.38766381,  0.78428014, -0.12911446],\n",
       "       [ 0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [ 1.84222365,  0.88189889,  0.11493111],\n",
       "       [-1.12563709, -0.52680338,  0.06564012],\n",
       "       [-2.71174416,  0.63290138,  0.71195473],\n",
       "       [-0.03100441, -0.20059783, -0.50339479],\n",
       "       [ 2.29618509,  0.07661447,  0.01087174],\n",
       "       [-0.61585248, -0.205764  ,  1.82651199],\n",
       "       [-1.73320252,  1.29971699,  0.09045178],\n",
       "       [-0.82366049, -0.57164535, -0.27123176],\n",
       "       [ 0.75619512,  0.73995175, -0.76710616],\n",
       "       [-0.42344386,  0.26555394, -1.41533681],\n",
       "       [-0.39581307, -1.64646874,  0.24104031],\n",
       "       [-0.88581498,  0.15195119, -0.82271209],\n",
       "       [ 0.24587691,  0.39139878, -1.15801831],\n",
       "       [ 0.14741103, -1.22874561, -0.03110396],\n",
       "       [-0.7161265 , -0.56781471, -0.86180345],\n",
       "       [ 0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MYPCA(X,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn 과의 차이 :\n",
    "sklearn에서 구한 고유벡터와 방향이 반대일 뿐, 같은 값을 반환함을 알 수 있음!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) MNIST data에 적용을 해볼게요!\n",
    "\n",
    "mnist data를 따로 내려받지 않게 압축파일에 같이 두었어요~!!!\n",
    "\n",
    "mnist-original.mat 파일과 같은 위치에서 주피터 노트북을 열어주세요~!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as lin\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from scipy import io\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# mnist 손글씨 데이터를 불러옵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = io.loadmat('mnist-original.mat') \n",
    "X = mnist['data'].T\n",
    "y = mnist['label'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data information\n",
    "\n",
    "# 7만개의 작은 숫자 이미지\n",
    "# 행 열이 반대로 되어있음 -> 전치\n",
    "# grayscale 28x28 pixel = 784 feature\n",
    "# 각 picel은 0~255의 값\n",
    "# label = 1~10 label이 총 10개인거에 주목하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data를 각 픽셀에 이름붙여 표현\n",
    "feat_cols = [ 'pixel'+str(i) for i in range(X.shape[1]) ]\n",
    "df = pd.DataFrame(X,columns=feat_cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df에 라벨 y를 붙여서 데이터프레임 생성\n",
    "df['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "2           0       0       0       0       0       0       0       0       0   \n",
       "3           0       0       0       0       0       0       0       0       0   \n",
       "4           0       0       0       0       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "69995       0       0       0       0       0       0       0       0       0   \n",
       "69996       0       0       0       0       0       0       0       0       0   \n",
       "69997       0       0       0       0       0       0       0       0       0   \n",
       "69998       0       0       0       0       0       0       0       0       0   \n",
       "69999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "69995       0  ...         0         0         0         0         0   \n",
       "69996       0  ...         0         0         0         0         0   \n",
       "69997       0  ...         0         0         0         0         0   \n",
       "69998       0  ...         0         0         0         0         0   \n",
       "69999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783    y  \n",
       "0             0         0         0         0  0.0  \n",
       "1             0         0         0         0  0.0  \n",
       "2             0         0         0         0  0.0  \n",
       "3             0         0         0         0  0.0  \n",
       "4             0         0         0         0  0.0  \n",
       "...         ...       ...       ...       ...  ...  \n",
       "69995         0         0         0         0  9.0  \n",
       "69996         0         0         0         0  9.0  \n",
       "69997         0         0         0         0  9.0  \n",
       "69998         0         0         0         0  9.0  \n",
       "69999         0         0         0         0  9.0  \n",
       "\n",
       "[70000 rows x 785 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 지금까지 배운 여러 머신러닝 기법들이 있을거에요\n",
    "\n",
    "4-1) train_test_split을 통해 데이터를 0.8 0.2의 비율로 분할 해 주시고요\n",
    "\n",
    "4-2) PCA를 이용하여 mnist data를 축소해서 학습을 해주세요 / test error가 제일 작으신 분께 상품을 드리겠습니다 ^0^\n",
    "\n",
    "특정한 틀 없이 자유롭게 하시면 됩니다!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-1) 데이터 셋 분리 \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Kaiser’s Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pca.explained_variance_\n",
    "x.shape # 총 784개의 피처"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = x >= 1\n",
    "x2 # 784개의 피처 중 1 이상의 값을 가지는 피처를 x2라 하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(x2) # x2의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0110790393510563\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=652)\n",
    "pca.fit(X_train)\n",
    "print(pca.explained_variance_.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9722171408739497\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=653)\n",
    "pca.fit(X_train)\n",
    "print(pca.explained_variance_.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_components=653 에서 처음으로 1보다 작은 값을 가짐을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaiser’s Rule을 통한 주성분 개수는 652개이므로 별 의미가 없어보입니당.\n",
    "elbow point와 누적설명률을 통해 찾아보도록 합시당"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Elbow-point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 653)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sing_vals = range(pca.n_components_)\n",
    "sing_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvals = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22b2953a488>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sing_vals, eigvals, 'ro-', color='skyblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0-100 사이에 elbow point가 존재하는 것 같은데,,\n",
    "잘 보이지 않으니 0-100 사이를 끊어서 다시 봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 100)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sing_vals, eigvals, 'ro-', color='skyblue')\n",
    "plt.xlim(0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 누적설명률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.731518852479176\n"
     ]
    }
   ],
   "source": [
    "# 주성분개수 30개\n",
    "cum_1 = 0\n",
    "i=0\n",
    "\n",
    "while(i<30):\n",
    "    cum_1 += eigvals[i]\n",
    "    i +=1\n",
    "\n",
    "print(cum_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7621154470990696\n"
     ]
    }
   ],
   "source": [
    "# 주성분개수 35개\n",
    "cum_2 = 0\n",
    "i=0\n",
    "\n",
    "while(i<35):\n",
    "    cum_2 += eigvals[i]\n",
    "    i +=1\n",
    "\n",
    "print(cum_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30~35개가 적당해 보입니당"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case1. n_components = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_30 = PCA(n_components = 30)\n",
    "X_30 = pca_30.fit_transform(X_train)\n",
    "X_test_30 = pca_30.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56000, 30)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_30.shape #x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56000, 1)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape #y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 30)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_30.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 1)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = lgb.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lcm01\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "model_lgb.fit(X_30, y_train)\n",
    "lgb_train_pred = model_lgb.predict(X_30)\n",
    "lgb_pred = model_lgb.predict(X_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8410185617573771"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgb.score(X_test_30, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "버리자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:21:58] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "model_xgb.fit(X_30, y_train)\n",
    "xgb_train_pred = model_xgb.predict(X_30)\n",
    "xgb_pred = model_xgb.predict(X_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7296666020804036"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.score(X_test_30, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "얘도 버리자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lcm01\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\lcm01\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "forest.fit(X_30, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9250714285714285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = forest.predict(X_test_30)\n",
    "print('Accuracy =', accuracy_score(y_test, y_pred))\n",
    "\n",
    "#forest.score(X_test, y_test)\n",
    "#metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.92 이지만 주성분 개수가 35인 경우도 확인해봅시담"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case2. n_components = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_40 = PCA(n_components = 40)\n",
    "X_40 = pca_40.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56000, 40)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_40.shape #확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lcm01\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\lcm01\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier()\n",
    "forest.fit(X_40, y_train)\n",
    "X_test_40 = pca_40.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lcm01\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\lcm01\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "forest.fit(X_40, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9266428571428571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = forest.predict(X_test_40)\n",
    "print('Accuracy =', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
