{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sampled_data.csv', encoding='cp949') #데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>136330</td>\n",
       "      <td>2.108286</td>\n",
       "      <td>-0.020359</td>\n",
       "      <td>-2.234273</td>\n",
       "      <td>-0.124080</td>\n",
       "      <td>0.559843</td>\n",
       "      <td>-1.315913</td>\n",
       "      <td>0.631887</td>\n",
       "      <td>-0.385490</td>\n",
       "      <td>0.150628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162940</td>\n",
       "      <td>0.519705</td>\n",
       "      <td>-0.091751</td>\n",
       "      <td>-0.379542</td>\n",
       "      <td>0.418822</td>\n",
       "      <td>0.248646</td>\n",
       "      <td>-0.098857</td>\n",
       "      <td>-0.094773</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>116819</td>\n",
       "      <td>2.080143</td>\n",
       "      <td>-0.075408</td>\n",
       "      <td>-1.359381</td>\n",
       "      <td>0.261263</td>\n",
       "      <td>0.232201</td>\n",
       "      <td>-0.797886</td>\n",
       "      <td>0.233487</td>\n",
       "      <td>-0.330165</td>\n",
       "      <td>0.493154</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.317765</td>\n",
       "      <td>-0.784150</td>\n",
       "      <td>0.233078</td>\n",
       "      <td>-0.636937</td>\n",
       "      <td>-0.191137</td>\n",
       "      <td>0.234986</td>\n",
       "      <td>-0.070648</td>\n",
       "      <td>-0.062794</td>\n",
       "      <td>17.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>27917</td>\n",
       "      <td>1.152650</td>\n",
       "      <td>0.204938</td>\n",
       "      <td>0.441832</td>\n",
       "      <td>1.211595</td>\n",
       "      <td>-0.254895</td>\n",
       "      <td>-0.383380</td>\n",
       "      <td>-0.004286</td>\n",
       "      <td>-0.019590</td>\n",
       "      <td>0.085094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066674</td>\n",
       "      <td>0.209828</td>\n",
       "      <td>-0.054351</td>\n",
       "      <td>0.058103</td>\n",
       "      <td>0.515330</td>\n",
       "      <td>-0.299402</td>\n",
       "      <td>0.032551</td>\n",
       "      <td>0.022865</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>97443</td>\n",
       "      <td>-0.389692</td>\n",
       "      <td>0.410148</td>\n",
       "      <td>0.616187</td>\n",
       "      <td>-0.686644</td>\n",
       "      <td>1.040312</td>\n",
       "      <td>-0.322199</td>\n",
       "      <td>0.523625</td>\n",
       "      <td>-0.037453</td>\n",
       "      <td>1.319237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116692</td>\n",
       "      <td>0.685267</td>\n",
       "      <td>-0.182303</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>-0.242738</td>\n",
       "      <td>0.009678</td>\n",
       "      <td>0.115370</td>\n",
       "      <td>0.176041</td>\n",
       "      <td>6.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17920</td>\n",
       "      <td>-1.306986</td>\n",
       "      <td>0.183306</td>\n",
       "      <td>3.164803</td>\n",
       "      <td>0.810135</td>\n",
       "      <td>1.529576</td>\n",
       "      <td>2.388322</td>\n",
       "      <td>0.551279</td>\n",
       "      <td>-0.054401</td>\n",
       "      <td>1.675481</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.203993</td>\n",
       "      <td>0.556523</td>\n",
       "      <td>0.146513</td>\n",
       "      <td>-1.128693</td>\n",
       "      <td>-0.633623</td>\n",
       "      <td>-0.454903</td>\n",
       "      <td>-0.826329</td>\n",
       "      <td>-0.826186</td>\n",
       "      <td>4.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0  136330  2.108286 -0.020359 -2.234273 -0.124080  0.559843 -1.315913   \n",
       "1  116819  2.080143 -0.075408 -1.359381  0.261263  0.232201 -0.797886   \n",
       "2   27917  1.152650  0.204938  0.441832  1.211595 -0.254895 -0.383380   \n",
       "3   97443 -0.389692  0.410148  0.616187 -0.686644  1.040312 -0.322199   \n",
       "4   17920 -1.306986  0.183306  3.164803  0.810135  1.529576  2.388322   \n",
       "\n",
       "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0  0.631887 -0.385490  0.150628  ...  0.162940  0.519705 -0.091751 -0.379542   \n",
       "1  0.233487 -0.330165  0.493154  ... -0.317765 -0.784150  0.233078 -0.636937   \n",
       "2 -0.004286 -0.019590  0.085094  ...  0.066674  0.209828 -0.054351  0.058103   \n",
       "3  0.523625 -0.037453  1.319237  ...  0.116692  0.685267 -0.182303  0.767857   \n",
       "4  0.551279 -0.054401  1.675481  ... -0.203993  0.556523  0.146513 -1.128693   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.418822  0.248646 -0.098857 -0.094773    7.70      0  \n",
       "1 -0.191137  0.234986 -0.070648 -0.062794   17.99      0  \n",
       "2  0.515330 -0.299402  0.032551  0.022865   21.00      0  \n",
       "3 -0.242738  0.009678  0.115370  0.176041    6.60      0  \n",
       "4 -0.633623 -0.454903 -0.826329 -0.826186    4.95      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() #데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.87599191,  1.10227326, -0.01383661, ..., -0.29889867,\n",
       "        -0.34162683, -0.04276894],\n",
       "       [ 0.46599202,  1.08762774, -0.04747727, ..., -0.19381068,\n",
       "        -0.29798293, -0.04276894],\n",
       "       [-1.4021752 ,  0.60496356,  0.12384231, ...,  0.08768119,\n",
       "        -0.28521635, -0.04276894],\n",
       "       ...,\n",
       "       [-0.42810237, -1.77186915, -0.42136644, ..., -0.90645255,\n",
       "         0.37580428, -0.04276894],\n",
       "       [ 0.90608364,  0.67055034, -1.06901447, ...,  0.00759972,\n",
       "         1.21623571, -0.04276894],\n",
       "       [-1.90993121,  0.72058018, -0.22056932, ...,  0.07781589,\n",
       "        -0.25934387, -0.04276894]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame(scaler.fit_transform(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.columns= ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', \n",
    "                 'V7', 'V8', 'V9', 'V10', 'V11', 'V12',\n",
    "                 'V13', 'V14', 'V15', 'V16', 'V17', 'V18',\n",
    "                 'V19', 'V20', 'V21', 'V22', 'V23', 'V24',\n",
    "                 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n",
    "# 열이름을 그대로 유지하는 법을 몰라서 다시 채워넣었습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.875992</td>\n",
       "      <td>1.102273</td>\n",
       "      <td>-0.013837</td>\n",
       "      <td>-1.519427</td>\n",
       "      <td>-0.092494</td>\n",
       "      <td>0.415984</td>\n",
       "      <td>-0.996862</td>\n",
       "      <td>0.529260</td>\n",
       "      <td>-0.325542</td>\n",
       "      <td>0.140034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217877</td>\n",
       "      <td>0.717147</td>\n",
       "      <td>-0.171055</td>\n",
       "      <td>-0.622575</td>\n",
       "      <td>0.811479</td>\n",
       "      <td>0.520065</td>\n",
       "      <td>-0.244661</td>\n",
       "      <td>-0.298899</td>\n",
       "      <td>-0.341627</td>\n",
       "      <td>-0.042769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.465992</td>\n",
       "      <td>1.087628</td>\n",
       "      <td>-0.047477</td>\n",
       "      <td>-0.930583</td>\n",
       "      <td>0.178984</td>\n",
       "      <td>0.173824</td>\n",
       "      <td>-0.604853</td>\n",
       "      <td>0.194623</td>\n",
       "      <td>-0.278678</td>\n",
       "      <td>0.453561</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.431114</td>\n",
       "      <td>-1.088996</td>\n",
       "      <td>0.399380</td>\n",
       "      <td>-1.044356</td>\n",
       "      <td>-0.370659</td>\n",
       "      <td>0.491879</td>\n",
       "      <td>-0.173318</td>\n",
       "      <td>-0.193811</td>\n",
       "      <td>-0.297983</td>\n",
       "      <td>-0.042769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1.402175</td>\n",
       "      <td>0.604964</td>\n",
       "      <td>0.123842</td>\n",
       "      <td>0.281721</td>\n",
       "      <td>0.848501</td>\n",
       "      <td>-0.186188</td>\n",
       "      <td>-0.291182</td>\n",
       "      <td>-0.005096</td>\n",
       "      <td>-0.015599</td>\n",
       "      <td>0.080048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087910</td>\n",
       "      <td>0.287896</td>\n",
       "      <td>-0.105378</td>\n",
       "      <td>0.094572</td>\n",
       "      <td>0.998518</td>\n",
       "      <td>-0.610760</td>\n",
       "      <td>0.087681</td>\n",
       "      <td>0.087681</td>\n",
       "      <td>-0.285216</td>\n",
       "      <td>-0.042769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.058829</td>\n",
       "      <td>-0.197667</td>\n",
       "      <td>0.249246</td>\n",
       "      <td>0.399070</td>\n",
       "      <td>-0.488826</td>\n",
       "      <td>0.771099</td>\n",
       "      <td>-0.244885</td>\n",
       "      <td>0.438324</td>\n",
       "      <td>-0.030730</td>\n",
       "      <td>1.209704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155438</td>\n",
       "      <td>0.946489</td>\n",
       "      <td>-0.330075</td>\n",
       "      <td>1.257612</td>\n",
       "      <td>-0.470666</td>\n",
       "      <td>0.026986</td>\n",
       "      <td>0.297138</td>\n",
       "      <td>0.591042</td>\n",
       "      <td>-0.346292</td>\n",
       "      <td>-0.042769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-1.612250</td>\n",
       "      <td>-0.675024</td>\n",
       "      <td>0.110623</td>\n",
       "      <td>2.114412</td>\n",
       "      <td>0.565669</td>\n",
       "      <td>1.132714</td>\n",
       "      <td>1.806258</td>\n",
       "      <td>0.461553</td>\n",
       "      <td>-0.045086</td>\n",
       "      <td>1.535788</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277512</td>\n",
       "      <td>0.768150</td>\n",
       "      <td>0.247363</td>\n",
       "      <td>-1.850173</td>\n",
       "      <td>-1.228224</td>\n",
       "      <td>-0.931617</td>\n",
       "      <td>-2.084501</td>\n",
       "      <td>-2.702442</td>\n",
       "      <td>-0.353291</td>\n",
       "      <td>-0.042769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28475</td>\n",
       "      <td>-1.269851</td>\n",
       "      <td>-0.303659</td>\n",
       "      <td>0.045113</td>\n",
       "      <td>1.652929</td>\n",
       "      <td>0.549944</td>\n",
       "      <td>-0.343748</td>\n",
       "      <td>1.176108</td>\n",
       "      <td>-0.300411</td>\n",
       "      <td>0.632508</td>\n",
       "      <td>0.600344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152658</td>\n",
       "      <td>0.798688</td>\n",
       "      <td>-0.012156</td>\n",
       "      <td>-0.489836</td>\n",
       "      <td>-0.263086</td>\n",
       "      <td>-0.676960</td>\n",
       "      <td>0.320643</td>\n",
       "      <td>0.103960</td>\n",
       "      <td>-0.148559</td>\n",
       "      <td>-0.042769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28476</td>\n",
       "      <td>0.717842</td>\n",
       "      <td>1.005432</td>\n",
       "      <td>-0.160124</td>\n",
       "      <td>-1.274450</td>\n",
       "      <td>0.223870</td>\n",
       "      <td>0.311822</td>\n",
       "      <td>-0.612151</td>\n",
       "      <td>0.464676</td>\n",
       "      <td>-0.280385</td>\n",
       "      <td>0.046481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111694</td>\n",
       "      <td>0.395568</td>\n",
       "      <td>-0.135871</td>\n",
       "      <td>-0.513670</td>\n",
       "      <td>0.430712</td>\n",
       "      <td>1.253071</td>\n",
       "      <td>-0.281188</td>\n",
       "      <td>-0.248409</td>\n",
       "      <td>-0.038367</td>\n",
       "      <td>-0.042769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28477</td>\n",
       "      <td>-0.428102</td>\n",
       "      <td>-1.771869</td>\n",
       "      <td>-0.421366</td>\n",
       "      <td>0.944253</td>\n",
       "      <td>-1.515500</td>\n",
       "      <td>0.294278</td>\n",
       "      <td>-0.779094</td>\n",
       "      <td>-2.189361</td>\n",
       "      <td>-2.011887</td>\n",
       "      <td>1.684925</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.046568</td>\n",
       "      <td>0.404609</td>\n",
       "      <td>-4.579363</td>\n",
       "      <td>0.428147</td>\n",
       "      <td>-0.572160</td>\n",
       "      <td>-0.415799</td>\n",
       "      <td>0.480802</td>\n",
       "      <td>-0.906453</td>\n",
       "      <td>0.375804</td>\n",
       "      <td>-0.042769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28478</td>\n",
       "      <td>0.906084</td>\n",
       "      <td>0.670550</td>\n",
       "      <td>-1.069014</td>\n",
       "      <td>-0.594471</td>\n",
       "      <td>0.304593</td>\n",
       "      <td>-0.827940</td>\n",
       "      <td>-0.147452</td>\n",
       "      <td>-0.270542</td>\n",
       "      <td>0.052176</td>\n",
       "      <td>0.971411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552837</td>\n",
       "      <td>0.515797</td>\n",
       "      <td>-0.295245</td>\n",
       "      <td>-0.511557</td>\n",
       "      <td>-1.032926</td>\n",
       "      <td>1.283600</td>\n",
       "      <td>-0.299928</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>1.216236</td>\n",
       "      <td>-0.042769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28479</td>\n",
       "      <td>-1.909931</td>\n",
       "      <td>0.720580</td>\n",
       "      <td>-0.220569</td>\n",
       "      <td>0.456264</td>\n",
       "      <td>-0.322366</td>\n",
       "      <td>-0.768278</td>\n",
       "      <td>-0.751067</td>\n",
       "      <td>-0.503880</td>\n",
       "      <td>-0.249034</td>\n",
       "      <td>0.433548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.315702</td>\n",
       "      <td>-0.796420</td>\n",
       "      <td>0.213515</td>\n",
       "      <td>0.490653</td>\n",
       "      <td>0.403848</td>\n",
       "      <td>-1.070219</td>\n",
       "      <td>-0.041204</td>\n",
       "      <td>0.077816</td>\n",
       "      <td>-0.259344</td>\n",
       "      <td>-0.042769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28480 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0      0.875992  1.102273 -0.013837 -1.519427 -0.092494  0.415984 -0.996862   \n",
       "1      0.465992  1.087628 -0.047477 -0.930583  0.178984  0.173824 -0.604853   \n",
       "2     -1.402175  0.604964  0.123842  0.281721  0.848501 -0.186188 -0.291182   \n",
       "3      0.058829 -0.197667  0.249246  0.399070 -0.488826  0.771099 -0.244885   \n",
       "4     -1.612250 -0.675024  0.110623  2.114412  0.565669  1.132714  1.806258   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "28475 -1.269851 -0.303659  0.045113  1.652929  0.549944 -0.343748  1.176108   \n",
       "28476  0.717842  1.005432 -0.160124 -1.274450  0.223870  0.311822 -0.612151   \n",
       "28477 -0.428102 -1.771869 -0.421366  0.944253 -1.515500  0.294278 -0.779094   \n",
       "28478  0.906084  0.670550 -1.069014 -0.594471  0.304593 -0.827940 -0.147452   \n",
       "28479 -1.909931  0.720580 -0.220569  0.456264 -0.322366 -0.768278 -0.751067   \n",
       "\n",
       "             V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0      0.529260 -0.325542  0.140034  ...  0.217877  0.717147 -0.171055   \n",
       "1      0.194623 -0.278678  0.453561  ... -0.431114 -1.088996  0.399380   \n",
       "2     -0.005096 -0.015599  0.080048  ...  0.087910  0.287896 -0.105378   \n",
       "3      0.438324 -0.030730  1.209704  ...  0.155438  0.946489 -0.330075   \n",
       "4      0.461553 -0.045086  1.535788  ... -0.277512  0.768150  0.247363   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "28475 -0.300411  0.632508  0.600344  ...  0.152658  0.798688 -0.012156   \n",
       "28476  0.464676 -0.280385  0.046481  ...  0.111694  0.395568 -0.135871   \n",
       "28477 -2.189361 -2.011887  1.684925  ... -2.046568  0.404609 -4.579363   \n",
       "28478 -0.270542  0.052176  0.971411  ...  0.552837  0.515797 -0.295245   \n",
       "28479 -0.503880 -0.249034  0.433548  ... -0.315702 -0.796420  0.213515   \n",
       "\n",
       "            V24       V25       V26       V27       V28    Amount     Class  \n",
       "0     -0.622575  0.811479  0.520065 -0.244661 -0.298899 -0.341627 -0.042769  \n",
       "1     -1.044356 -0.370659  0.491879 -0.173318 -0.193811 -0.297983 -0.042769  \n",
       "2      0.094572  0.998518 -0.610760  0.087681  0.087681 -0.285216 -0.042769  \n",
       "3      1.257612 -0.470666  0.026986  0.297138  0.591042 -0.346292 -0.042769  \n",
       "4     -1.850173 -1.228224 -0.931617 -2.084501 -2.702442 -0.353291 -0.042769  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "28475 -0.489836 -0.263086 -0.676960  0.320643  0.103960 -0.148559 -0.042769  \n",
       "28476 -0.513670  0.430712  1.253071 -0.281188 -0.248409 -0.038367 -0.042769  \n",
       "28477  0.428147 -0.572160 -0.415799  0.480802 -0.906453  0.375804 -0.042769  \n",
       "28478 -0.511557 -1.032926  1.283600 -0.299928  0.007600  1.216236 -0.042769  \n",
       "28479  0.490653  0.403848 -1.070219 -0.041204  0.077816 -0.259344 -0.042769  \n",
       "\n",
       "[28480 rows x 31 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new #확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.218431    5\n",
       "-0.972317    4\n",
       " 1.367946    4\n",
       " 0.989697    4\n",
       "-1.909931    4\n",
       "            ..\n",
       " 0.649884    1\n",
       " 0.649989    1\n",
       " 0.650052    1\n",
       " 0.650094    1\n",
       "-1.988565    1\n",
       "Name: class, Length: 25695, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled Data\n",
    "df_new['class'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.875992</td>\n",
       "      <td>1.102273</td>\n",
       "      <td>-0.013837</td>\n",
       "      <td>-1.519427</td>\n",
       "      <td>-0.092494</td>\n",
       "      <td>0.415984</td>\n",
       "      <td>-0.996862</td>\n",
       "      <td>0.529260</td>\n",
       "      <td>-0.325542</td>\n",
       "      <td>0.140034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717147</td>\n",
       "      <td>-0.171055</td>\n",
       "      <td>-0.622575</td>\n",
       "      <td>0.811479</td>\n",
       "      <td>0.520065</td>\n",
       "      <td>-0.244661</td>\n",
       "      <td>-0.298899</td>\n",
       "      <td>-0.341627</td>\n",
       "      <td>-0.042769</td>\n",
       "      <td>0.875992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.465992</td>\n",
       "      <td>1.087628</td>\n",
       "      <td>-0.047477</td>\n",
       "      <td>-0.930583</td>\n",
       "      <td>0.178984</td>\n",
       "      <td>0.173824</td>\n",
       "      <td>-0.604853</td>\n",
       "      <td>0.194623</td>\n",
       "      <td>-0.278678</td>\n",
       "      <td>0.453561</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.088996</td>\n",
       "      <td>0.399380</td>\n",
       "      <td>-1.044356</td>\n",
       "      <td>-0.370659</td>\n",
       "      <td>0.491879</td>\n",
       "      <td>-0.173318</td>\n",
       "      <td>-0.193811</td>\n",
       "      <td>-0.297983</td>\n",
       "      <td>-0.042769</td>\n",
       "      <td>0.465992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1.402175</td>\n",
       "      <td>0.604964</td>\n",
       "      <td>0.123842</td>\n",
       "      <td>0.281721</td>\n",
       "      <td>0.848501</td>\n",
       "      <td>-0.186188</td>\n",
       "      <td>-0.291182</td>\n",
       "      <td>-0.005096</td>\n",
       "      <td>-0.015599</td>\n",
       "      <td>0.080048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287896</td>\n",
       "      <td>-0.105378</td>\n",
       "      <td>0.094572</td>\n",
       "      <td>0.998518</td>\n",
       "      <td>-0.610760</td>\n",
       "      <td>0.087681</td>\n",
       "      <td>0.087681</td>\n",
       "      <td>-0.285216</td>\n",
       "      <td>-0.042769</td>\n",
       "      <td>-1.402175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.058829</td>\n",
       "      <td>-0.197667</td>\n",
       "      <td>0.249246</td>\n",
       "      <td>0.399070</td>\n",
       "      <td>-0.488826</td>\n",
       "      <td>0.771099</td>\n",
       "      <td>-0.244885</td>\n",
       "      <td>0.438324</td>\n",
       "      <td>-0.030730</td>\n",
       "      <td>1.209704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946489</td>\n",
       "      <td>-0.330075</td>\n",
       "      <td>1.257612</td>\n",
       "      <td>-0.470666</td>\n",
       "      <td>0.026986</td>\n",
       "      <td>0.297138</td>\n",
       "      <td>0.591042</td>\n",
       "      <td>-0.346292</td>\n",
       "      <td>-0.042769</td>\n",
       "      <td>0.058829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-1.612250</td>\n",
       "      <td>-0.675024</td>\n",
       "      <td>0.110623</td>\n",
       "      <td>2.114412</td>\n",
       "      <td>0.565669</td>\n",
       "      <td>1.132714</td>\n",
       "      <td>1.806258</td>\n",
       "      <td>0.461553</td>\n",
       "      <td>-0.045086</td>\n",
       "      <td>1.535788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768150</td>\n",
       "      <td>0.247363</td>\n",
       "      <td>-1.850173</td>\n",
       "      <td>-1.228224</td>\n",
       "      <td>-0.931617</td>\n",
       "      <td>-2.084501</td>\n",
       "      <td>-2.702442</td>\n",
       "      <td>-0.353291</td>\n",
       "      <td>-0.042769</td>\n",
       "      <td>-1.612250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0  0.875992  1.102273 -0.013837 -1.519427 -0.092494  0.415984 -0.996862   \n",
       "1  0.465992  1.087628 -0.047477 -0.930583  0.178984  0.173824 -0.604853   \n",
       "2 -1.402175  0.604964  0.123842  0.281721  0.848501 -0.186188 -0.291182   \n",
       "3  0.058829 -0.197667  0.249246  0.399070 -0.488826  0.771099 -0.244885   \n",
       "4 -1.612250 -0.675024  0.110623  2.114412  0.565669  1.132714  1.806258   \n",
       "\n",
       "         V7        V8        V9  ...       V22       V23       V24       V25  \\\n",
       "0  0.529260 -0.325542  0.140034  ...  0.717147 -0.171055 -0.622575  0.811479   \n",
       "1  0.194623 -0.278678  0.453561  ... -1.088996  0.399380 -1.044356 -0.370659   \n",
       "2 -0.005096 -0.015599  0.080048  ...  0.287896 -0.105378  0.094572  0.998518   \n",
       "3  0.438324 -0.030730  1.209704  ...  0.946489 -0.330075  1.257612 -0.470666   \n",
       "4  0.461553 -0.045086  1.535788  ...  0.768150  0.247363 -1.850173 -1.228224   \n",
       "\n",
       "        V26       V27       V28    Amount     Class     class  \n",
       "0  0.520065 -0.244661 -0.298899 -0.341627 -0.042769  0.875992  \n",
       "1  0.491879 -0.173318 -0.193811 -0.297983 -0.042769  0.465992  \n",
       "2 -0.610760  0.087681  0.087681 -0.285216 -0.042769 -1.402175  \n",
       "3  0.026986  0.297138  0.591042 -0.346292 -0.042769  0.058829  \n",
       "4 -0.931617 -2.084501 -2.702442 -0.353291 -0.042769 -1.612250  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로지스틱 회귀분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], df.iloc[:, -1], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21360, 31), (7120, 31), (21360,), (7120,))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lcm01\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-823006b8c854>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1531\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m   1532\u001b[0m                          accept_large_sparse=solver != 'liblinear')\n\u001b[1;32m-> 1533\u001b[1;33m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1534\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1535\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    167\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[0;32m    168\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegression instance is not fitted yet",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-aa24af539720>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# class 예측\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \"\"\"\n\u001b[1;32m--> 289\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coef_'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             raise NotFittedError(\"This %(name)s instance is not fitted \"\n\u001b[1;32m--> 263\u001b[1;33m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This LogisticRegression instance is not fitted yet"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test) # class 예측\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Call fit before prediction",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-aa6b2e1bb1d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1646\u001b[0m         \"\"\"\n\u001b[0;32m   1647\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coef_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1648\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Call fit before prediction\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1650\u001b[0m         ovr = (self.multi_class in [\"ovr\", \"warn\"] or\n",
      "\u001b[1;31mNotFittedError\u001b[0m: Call fit before prediction"
     ]
    }
   ],
   "source": [
    "classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegression instance is not fitted yet",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-3e285ad08048>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#mean accuracy를 구하자\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    355\u001b[0m         \"\"\"\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \"\"\"\n\u001b[1;32m--> 289\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coef_'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             raise NotFittedError(\"This %(name)s instance is not fitted \"\n\u001b[1;32m--> 263\u001b[1;33m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This LogisticRegression instance is not fitted yet"
     ]
    }
   ],
   "source": [
    "classifier.score(X_test, y_test) #mean accuracy를 구하자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scalesd Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(df_new.iloc[:, :-1], df_new.iloc[:, -1], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lcm01\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-d6eb82083fc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclassifier2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclassifier2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1531\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m   1532\u001b[0m                          accept_large_sparse=solver != 'liblinear')\n\u001b[1;32m-> 1533\u001b[1;33m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1534\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1535\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    167\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[0;32m    168\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "classifier2 = LogisticRegression()\n",
    "classifier2.fit(X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegression instance is not fitted yet",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-5c1574704b73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# class 예측\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_pred2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \"\"\"\n\u001b[1;32m--> 289\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coef_'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             raise NotFittedError(\"This %(name)s instance is not fitted \"\n\u001b[1;32m--> 263\u001b[1;33m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This LogisticRegression instance is not fitted yet"
     ]
    }
   ],
   "source": [
    "y_pred2 = classifier2.predict(X_test2) # class 예측\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-41-1ec50abab32d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-41-1ec50abab32d>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    classifier2.score(X_test2, y_test2\u001b[0m\n\u001b[1;37m                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "classifier2.score(X_test2, y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
